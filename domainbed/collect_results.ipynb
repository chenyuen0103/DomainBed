{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T03:27:16.901622Z",
     "start_time": "2024-05-04T03:27:16.897454Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import glob\n",
    "import pickle\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If domainbed is a custom module, you might need to adjust its imports or setup\n",
    "from domainbed import datasets\n",
    "from domainbed import algorithms\n",
    "from domainbed.lib import misc, reporting\n",
    "from domainbed import model_selection\n",
    "from domainbed.lib.query import Q\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def get_test_records(records):\n",
    "    \"\"\"Given records with a common test env, get the test records (i.e. the\n",
    "    records with *only* that single test env and no other test envs)\"\"\"\n",
    "    return records.filter(lambda r: len(r['args']['test_envs']) == 1)\n",
    "\n",
    "class SelectionMethod:\n",
    "    \"\"\"Abstract class whose subclasses implement strategies for model\n",
    "    selection across hparams and timesteps.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        raise TypeError\n",
    "\n",
    "    @classmethod\n",
    "    def run_acc(self, run_records):\n",
    "        \"\"\"\n",
    "        Given records from a run, return a {val_acc, test_acc} dict representing\n",
    "        the best val-acc and corresponding test-acc for that run.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def hparams_accs(self, records):\n",
    "        \"\"\"\n",
    "        Given all records from a single (dataset, algorithm, test env) pair,\n",
    "        return a sorted list of (run_acc, records) tuples.\n",
    "        \"\"\"\n",
    "\n",
    "        return (records.group('args.hparams_seed')\n",
    "            .map(lambda _, run_records:\n",
    "                (\n",
    "                    self.run_acc(run_records),\n",
    "                    run_records\n",
    "                )\n",
    "            ).filter(lambda x: x[0] is not None)\n",
    "            .sorted(key=lambda x: x[0]['val_acc'])[::-1]\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def sweep_acc(self, records):\n",
    "        \"\"\"\n",
    "        Given all records from a single (dataset, algorithm, test env) pair,\n",
    "        return the mean test acc of the k runs with the top val accs.\n",
    "        \"\"\"\n",
    "        _hparams_accs = self.hparams_accs(records)\n",
    "        a = _hparams_accs\n",
    "        # for i in range(len(a)):\n",
    "        #     print(a[i][0]['val_acc'], a[i][0]['test_acc'])\n",
    "        #     print(f\"Hparams {(a[i][1][0]['hparams']['grad_alpha'], a[i][1][0]['hparams']['grad_alpha'],  a[i][1][0]['hparams']['penalty_anneal_iters'])}\")\n",
    "        # if a[0][1][0]['args']['algorithm'] == 'Fishr':\n",
    "        # if a[0][1][0]['args']['algorithm'] == 'HessianAlignment':\n",
    "        #     print(f\"Algorithm: {a[0][1][0]['args']['algorithm']}\")\n",
    "        #     print(f\"Best val acc and test for {a[0][1][0]['args']['dataset']}, env {a[0][1][0]['args']['test_envs']}:\", a[0][0]['val_acc'], a[0][0]['test_acc']) \n",
    "        #     print(f\"Best hyperparameters for {a[0][1][0]['args']['dataset']}, env {a[0][1][0]['args']['test_envs']}:\", a[0][1][0]['hparams'])\n",
    "\n",
    "        if len(_hparams_accs):\n",
    "            # breakpoint()\n",
    "            return _hparams_accs[0][0]['test_acc']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "class OracleSelectionMethod(SelectionMethod):\n",
    "    \"\"\"Like Selection method which picks argmax(test_out_acc) across all hparams\n",
    "    and checkpoints, but instead of taking the argmax over all\n",
    "    checkpoints, we pick the last checkpoint, i.e. no early stopping.\"\"\"\n",
    "    name = \"test-domain validation set (oracle)\"\n",
    "\n",
    "    @classmethod\n",
    "    def run_acc(self, run_records):\n",
    "        run_records = run_records.filter(lambda r:\n",
    "            len(r['args']['test_envs']) == 1)\n",
    "        if not len(run_records):\n",
    "            return None\n",
    "        test_env = run_records[0]['args']['test_envs'][0]\n",
    "        test_out_acc_key = 'env{}_out_acc'.format(test_env)\n",
    "        test_in_acc_key = 'env{}_in_acc'.format(test_env)\n",
    "        chosen_record = run_records.sorted(lambda r: r['step'])[-1]\n",
    "        return {\n",
    "            'val_acc':  chosen_record[test_out_acc_key],\n",
    "            'test_acc': chosen_record[test_in_acc_key]\n",
    "        }\n",
    "\n",
    "class IIDAccuracySelectionMethod(SelectionMethod):\n",
    "    \"\"\"Picks argmax(mean(env_out_acc for env in train_envs))\"\"\"\n",
    "    name = \"training-domain validation set\"\n",
    "\n",
    "    @classmethod\n",
    "    def _step_acc(self, record):\n",
    "        \"\"\"Given a single record, return a {val_acc, test_acc} dict.\"\"\"\n",
    "        test_env = record['args']['test_envs'][0]\n",
    "        val_env_keys = []\n",
    "        for i in itertools.count():\n",
    "            if f'env{i}_out_acc' not in record:\n",
    "                break\n",
    "            if i != test_env:\n",
    "                val_env_keys.append(f'env{i}_out_acc')\n",
    "        test_in_acc_key = 'env{}_in_acc'.format(test_env)\n",
    "        return {\n",
    "            'val_acc': np.mean([record[key] for key in val_env_keys]),\n",
    "            'test_acc': record[test_in_acc_key]\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def run_acc(self, run_records):\n",
    "        test_records = get_test_records(run_records)\n",
    "        if not len(test_records):\n",
    "            return None\n",
    "\n",
    "        index_of_max = test_records.map(self._step_acc).map(lambda x: x['val_acc'])._list.index(\n",
    "            max(test_records.map(self._step_acc).map(lambda x: x['val_acc'])))\n",
    "        full_record_with_hyperparams = test_records[index_of_max]\n",
    "        # print(f\"Hyperparameters for {full_record_with_hyperparams['args']['dataset']}, env {full_record_with_hyperparams['args']['test_envs']}:\", full_record_with_hyperparams['hparams'])\n",
    "        return test_records.map(self._step_acc).argmax('val_acc')\n",
    "\n",
    "class LeaveOneOutSelectionMethod(SelectionMethod):\n",
    "    \"\"\"Picks (hparams, step) by leave-one-out cross validation.\"\"\"\n",
    "    name = \"leave-one-domain-out cross-validation\"\n",
    "\n",
    "    @classmethod\n",
    "    def _step_acc(self, records):\n",
    "        \"\"\"Return the {val_acc, test_acc} for a group of records corresponding\n",
    "        to a single step.\"\"\"\n",
    "        test_records = get_test_records(records)\n",
    "        if len(test_records) != 1:\n",
    "            return None\n",
    "\n",
    "        test_env = test_records[0]['args']['test_envs'][0]\n",
    "        n_envs = 0\n",
    "        for i in itertools.count():\n",
    "            if f'env{i}_out_acc' not in records[0]:\n",
    "                break\n",
    "            n_envs += 1\n",
    "        val_accs = np.zeros(n_envs) - 1\n",
    "        for r in records.filter(lambda r: len(r['args']['test_envs']) == 2):\n",
    "            val_env = (set(r['args']['test_envs']) - set([test_env])).pop()\n",
    "            val_accs[val_env] = r['env{}_in_acc'.format(val_env)]\n",
    "        val_accs = list(val_accs[:test_env]) + list(val_accs[test_env+1:])\n",
    "        if any([v==-1 for v in val_accs]):\n",
    "            return None\n",
    "        val_acc = np.sum(val_accs) / (n_envs-1)\n",
    "        return {\n",
    "            'val_acc': val_acc,\n",
    "            'test_acc': test_records[0]['env{}_in_acc'.format(test_env)]\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def run_acc(self, records):\n",
    "        step_accs = records.group('step').map(lambda step, step_records:\n",
    "            self._step_acc(step_records)\n",
    "        ).filter_not_none()\n",
    "        if len(step_accs):\n",
    "            return step_accs.argmax('val_acc')\n",
    "        else:\n",
    "            return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T05:08:49.811523Z",
     "start_time": "2024-05-07T05:08:49.807865Z"
    }
   },
   "id": "9a40c1c70267ef5f",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subdirectories: 945\n",
      "Empty subdirectories: 601\n"
     ]
    }
   ],
   "source": [
    "def count_subdirectories_and_empty_ones(directory):\n",
    "    \n",
    "    num_subdirectories = 0\n",
    "    num_empty_subdirectories = 0\n",
    "\n",
    "    # Walk through all directories in the given directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Iterate over each directory in the current root\n",
    "        for d in dirs:\n",
    "            num_subdirectories += 1\n",
    "            subdirectory_path = os.path.join(root, d)\n",
    "            # Check if the directory is empty\n",
    "            if not os.listdir(subdirectory_path):\n",
    "                num_empty_subdirectories += 1\n",
    "\n",
    "    return num_subdirectories, num_empty_subdirectories\n",
    "\n",
    "\n",
    "# Specify the directory you want to inspect\n",
    "directory_path = 'results_vits_3600_32'\n",
    "\n",
    "# Get the count of subdirectories and empty subdirectories\n",
    "subdirectories, empty_subdirectories = count_subdirectories_and_empty_ones(directory_path)\n",
    "print(f\"Total subdirectories: {subdirectories}\")\n",
    "print(f\"Empty subdirectories: {empty_subdirectories}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T03:38:14.098502Z",
     "start_time": "2024-05-08T03:38:14.049961Z"
    }
   },
   "id": "8ab783a36ad7a66e",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_mean(data, latex):\n",
    "    \"\"\"Given a list of datapoints, return a string describing their mean and\n",
    "    standard error\"\"\"\n",
    "    if len(data) == 0:\n",
    "        return None, None, \"X\"\n",
    "    mean = 100 * np.mean(list(data))\n",
    "    err = 100 * np.std(list(data) / np.sqrt(len(data)))\n",
    "    if latex:\n",
    "        return mean, err, \"{:.1f} $\\\\pm$ {:.1f}\".format(mean, err)\n",
    "    else:\n",
    "        return mean, err, \"{:.1f} +/- {:.1f}\".format(mean, err)\n",
    "\n",
    "def print_table(table, header_text, row_labels, col_labels, colwidth=10,\n",
    "    latex=True):\n",
    "    \"\"\"Pretty-print a 2D array of data, optionally with row/col labels\"\"\"\n",
    "    print(\"\")\n",
    "\n",
    "    if latex:\n",
    "        num_cols = len(table[0])\n",
    "        print(\"\\\\begin{center}\")\n",
    "        print(\"\\\\adjustbox{max width=\\\\textwidth}{%\")\n",
    "        print(\"\\\\begin{tabular}{l\" + \"c\" * num_cols + \"}\")\n",
    "        print(\"\\\\toprule\")\n",
    "    else:\n",
    "        print(\"--------\", header_text)\n",
    "\n",
    "    for row, label in zip(table, row_labels):\n",
    "        row.insert(0, label)\n",
    "\n",
    "    if latex:\n",
    "        col_labels = [\"\\\\textbf{\" + str(col_label).replace(\"%\", \"\\\\%\") + \"}\"\n",
    "            for col_label in col_labels]\n",
    "    table.insert(0, col_labels)\n",
    "\n",
    "    for r, row in enumerate(table):\n",
    "        misc.print_row(row, colwidth=colwidth, latex=latex)\n",
    "        if latex and r == 0:\n",
    "            print(\"\\\\midrule\")\n",
    "    if latex:\n",
    "        print(\"\\\\bottomrule\")\n",
    "        print(\"\\\\end{tabular}}\")\n",
    "        print(\"\\\\end{center}\")\n",
    "\n",
    "def print_results_tables(records, selection_method, latex):\n",
    "    \"\"\"Given all records, print a results table for each dataset.\"\"\"\n",
    "    grouped_records = reporting.get_grouped_records(records).map(lambda group:\n",
    "        { **group, \"sweep_acc\": selection_method.sweep_acc(group[\"records\"]) }\n",
    "    ).filter(lambda g: g[\"sweep_acc\"] is not None)\n",
    "\n",
    "    # read algorithm names and sort (predefined order)\n",
    "    alg_names = Q(records).select(\"args.algorithm\").unique()\n",
    "    alg_names = ([n for n in algorithms.ALGORITHMS if n in alg_names] +\n",
    "        [n for n in alg_names if n not in algorithms.ALGORITHMS])\n",
    "\n",
    "    # read dataset names and sort (lexicographic order)\n",
    "    dataset_names = Q(records).select(\"args.dataset\").unique().sorted()\n",
    "    dataset_names = [d for d in datasets.DATASETS if d in dataset_names]\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        if latex:\n",
    "            print()\n",
    "            print(\"\\\\subsubsection{{{}}}\".format(dataset))\n",
    "        test_envs = range(datasets.num_environments(dataset))\n",
    "        # breakpoint()\n",
    "        table = [[None for _ in [*test_envs, \"Avg\"]] for _ in alg_names]\n",
    "        for i, algorithm in enumerate(alg_names):\n",
    "            means = []\n",
    "            for j, test_env in enumerate(test_envs):\n",
    "                trial_accs = (grouped_records\n",
    "                    .filter_equals(\n",
    "                        \"dataset, algorithm, test_env\",\n",
    "                        (dataset, algorithm, test_env)\n",
    "                    ).select(\"sweep_acc\"))\n",
    "                mean, err, table[i][j] = format_mean(trial_accs, latex)\n",
    "                means.append(mean)\n",
    "            if None in means:\n",
    "                table[i][-1] = \"X\"\n",
    "            else:\n",
    "                table[i][-1] = \"{:.1f}\".format(sum(means) / len(means))\n",
    "\n",
    "        col_labels = [\n",
    "            \"Algorithm\",\n",
    "            *datasets.get_dataset_class(dataset).ENVIRONMENTS,\n",
    "            \"Avg\"\n",
    "        ]\n",
    "        header_text = (f\"Dataset: {dataset}, \"\n",
    "            f\"model selection method: {selection_method.name}\")\n",
    "        print_table(table, header_text, alg_names, list(col_labels),\n",
    "            colwidth=20, latex=latex)\n",
    "\n",
    "    # Print an \"averages\" table\n",
    "    if latex:\n",
    "        print()\n",
    "        print(\"\\\\subsubsection{Averages}\")\n",
    "\n",
    "    table = [[None for _ in [*dataset_names, \"Avg\"]] for _ in alg_names]\n",
    "    for i, algorithm in enumerate(alg_names):\n",
    "        means = []\n",
    "        for j, dataset in enumerate(dataset_names):\n",
    "            trial_averages = (grouped_records\n",
    "                .filter_equals(\"algorithm, dataset\", (algorithm, dataset))\n",
    "                .group(\"trial_seed\")\n",
    "                .map(lambda trial_seed, group:\n",
    "                    group.select(\"sweep_acc\").mean()\n",
    "                )\n",
    "            )\n",
    "            mean, err, table[i][j] = format_mean(trial_averages, latex)\n",
    "            means.append(mean)\n",
    "        if None in means:\n",
    "            table[i][-1] = \"X\"\n",
    "        else:\n",
    "            table[i][-1] = \"{:.1f}\".format(sum(means) / len(means))\n",
    "\n",
    "    col_labels = [\"Algorithm\", *dataset_names, \"Avg\"]\n",
    "    header_text = f\"Averages, model selection method: {selection_method.name}\"\n",
    "    print_table(table, header_text, alg_names, col_labels, colwidth=25,\n",
    "        latex=latex)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T03:38:15.057033Z",
     "start_time": "2024-05-08T03:38:15.055597Z"
    }
   },
   "id": "73ca9d266f0c31a8",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- Dataset: ColoredMNIST, model selection method: training-domain validation set\n",
      "Algorithm             +90%                  +80%                  -90%                  Avg                  \n",
      "ERM                   71.4 +/- 0.4          72.7 +/- 0.2          10.1 +/- 0.2          51.4                 \n",
      "Fishr                 73.1 +/- 0.2          73.1 +/- 0.3          10.2 +/- 0.1          52.1                 \n",
      "HessianAlignment      72.2 +/- 0.2          73.3 +/- 0.3          10.0 +/- 0.3          51.8                 \n",
      "\n",
      "-------- Dataset: RotatedMNIST, model selection method: training-domain validation set\n",
      "Algorithm             0                     15                    30                    45                    60                    75                    Avg                  \n",
      "ERM                   93.9 +/- 0.8          98.5 +/- 0.1          99.1 +/- 0.1          98.9 +/- 0.1          98.9 +/- 0.0          95.6 +/- 0.7          97.5                 \n",
      "Fishr                 93.5 +/- 0.7          98.2 +/- 0.3          99.1 +/- 0.1          99.0 +/- 0.1          98.8 +/- 0.1          95.5 +/- 0.7          97.3                 \n",
      "HessianAlignment      94.6 +/- 0.6          98.6 +/- 0.2          99.0 +/- 0.0          98.6 +/- 0.3          98.3 +/- 0.3          95.3 +/- 0.6          97.4                 \n",
      "\n",
      "-------- Dataset: VLCS, model selection method: training-domain validation set\n",
      "Algorithm             C                     L                     S                     V                     Avg                  \n",
      "ERM                   94.3 +/- 0.7          62.7 +/- 0.5          70.3 +/- 1.9          75.2 +/- 1.4          75.6                 \n",
      "Fishr                 94.9 +/- 0.1          63.0 +/- 0.9          75.2 +/- 0.8          75.6 +/- 0.8          77.2                 \n",
      "HessianAlignment      96.5 +/- 0.4          61.4 +/- 0.8          74.5 +/- 0.2          77.0 +/- 0.6          77.4                 \n",
      "\n",
      "-------- Dataset: PACS, model selection method: training-domain validation set\n",
      "Algorithm             A                     C                     P                     S                     Avg                  \n",
      "ERM                   74.2 +/- 5.1          71.4 +/- 2.0          95.1 +/- 0.4          64.7 +/- 1.4          76.4                 \n",
      "Fishr                 82.8 +/- 1.2          76.1 +/- 1.1          97.0 +/- 0.4          64.1 +/- 2.4          80.0                 \n",
      "HessianAlignment      82.9 +/- 0.8          73.3 +/- 2.9          89.7 +/- 5.3          66.6 +/- 2.0          78.1                 \n",
      "\n",
      "-------- Dataset: TerraIncognita, model selection method: training-domain validation set\n",
      "Algorithm             L100                  L38                   L43                   L46                   Avg                  \n",
      "ERM                   34.5 +/- 11.2         23.3 +/- 3.8          36.5 +/- 1.0          34.6 +/- 0.2          32.2                 \n",
      "Fishr                 43.6 +/- 3.0          15.4 +/- 0.0          37.6 +/- 1.0          34.2 +/- 1.7          32.7                 \n",
      "HessianAlignment      48.3 +/- 1.0          19.6 +/- 1.9          35.9 +/- 1.2          29.8 +/- 1.2          33.4                 \n",
      "\n",
      "-------- Averages, model selection method: training-domain validation set\n",
      "Algorithm                  ColoredMNIST               RotatedMNIST               VLCS                       PACS                       TerraIncognita             Avg                       \n",
      "ERM                        58.2 +/- 5.6               97.7 +/- 0.3               73.7 +/- 1.4               76.4 +/- 2.0               32.4 +/- 2.0               67.7                      \n",
      "Fishr                      59.1 +/- 5.5               97.3 +/- 0.3               74.8 +/- 2.1               79.7 +/- 0.6               31.8 +/- 3.9               68.5                      \n",
      "HessianAlignment           58.6 +/- 5.5               97.4 +/- 0.2               75.2 +/- 1.9               77.0 +/- 3.2               31.4 +/- 1.7               67.9                      \n",
      "\n",
      "-------- Dataset: ColoredMNIST, model selection method: test-domain validation set (oracle)\n",
      "Algorithm             +90%                  +80%                  -90%                  Avg                  \n",
      "ERM                   65.8 +/- 1.2          69.0 +/- 0.9          25.0 +/- 2.9          53.3                 \n",
      "Fishr                 72.4 +/- 1.5          73.2 +/- 0.4          26.2 +/- 1.0          57.3                 \n",
      "HessianAlignment      68.7 +/- 0.4          67.6 +/- 0.2          25.7 +/- 2.0          54.0                 \n",
      "\n",
      "-------- Dataset: RotatedMNIST, model selection method: test-domain validation set (oracle)\n",
      "Algorithm             0                     15                    30                    45                    60                    75                    Avg                  \n",
      "ERM                   93.8 +/- 0.7          98.4 +/- 0.1          99.1 +/- 0.1          98.7 +/- 0.2          98.8 +/- 0.0          94.5 +/- 0.9          97.2                 \n",
      "Fishr                 94.7 +/- 0.3          98.4 +/- 0.3          98.8 +/- 0.1          99.0 +/- 0.1          98.8 +/- 0.2          95.3 +/- 0.6          97.5                 \n",
      "HessianAlignment      94.5 +/- 0.8          98.5 +/- 0.4          98.7 +/- 0.1          98.7 +/- 0.3          98.1 +/- 0.4          94.5 +/- 1.0          97.2                 \n",
      "\n",
      "-------- Dataset: VLCS, model selection method: test-domain validation set (oracle)\n",
      "Algorithm             C                     L                     S                     V                     Avg                  \n",
      "ERM                   90.2 +/- 3.1          62.1 +/- 0.7          66.6 +/- 4.7          74.7 +/- 1.1          73.4                 \n",
      "Fishr                 95.2 +/- 0.1          62.3 +/- 0.8          71.8 +/- 0.1          75.2 +/- 0.3          76.1                 \n",
      "HessianAlignment      95.3 +/- 0.2          59.8 +/- 1.4          72.6 +/- 1.1          75.8 +/- 1.6          75.9                 \n",
      "\n",
      "-------- Dataset: PACS, model selection method: test-domain validation set (oracle)\n",
      "Algorithm             A                     C                     P                     S                     Avg                  \n",
      "ERM                   71.2 +/- 8.4          68.1 +/- 2.7          95.1 +/- 0.2          64.7 +/- 1.3          74.8                 \n",
      "Fishr                 83.5 +/- 0.0          76.1 +/- 0.6          96.8 +/- 0.5          66.7 +/- 1.5          80.8                 \n",
      "HessianAlignment      82.8 +/- 1.3          71.5 +/- 3.9          89.3 +/- 6.1          70.3 +/- 0.5          78.5                 \n",
      "\n",
      "-------- Dataset: TerraIncognita, model selection method: test-domain validation set (oracle)\n",
      "Algorithm             L100                  L38                   L43                   L46                   Avg                  \n",
      "ERM                   39.5 +/- 7.0          23.1 +/- 1.6          35.8 +/- 1.3          32.9 +/- 0.6          32.8                 \n",
      "Fishr                 40.5 +/- 3.0          14.9 +/- 0.3          38.0 +/- 1.3          33.4 +/- 1.8          31.7                 \n",
      "HessianAlignment      50.0 +/- 2.0          20.7 +/- 2.3          35.0 +/- 1.4          32.7 +/- 0.8          34.6                 \n",
      "\n",
      "-------- Averages, model selection method: test-domain validation set (oracle)\n",
      "Algorithm                  ColoredMNIST               RotatedMNIST               VLCS                       PACS                       TerraIncognita             Avg                       \n",
      "ERM                        57.6 +/- 3.7               97.5 +/- 0.3               71.8 +/- 1.7               74.8 +/- 2.8               33.0 +/- 0.5               66.9                      \n",
      "Fishr                      62.2 +/- 3.5               97.5 +/- 0.2               74.0 +/- 1.7               80.5 +/- 0.4               30.8 +/- 4.0               69.0                      \n",
      "HessianAlignment           58.9 +/- 4.0               97.2 +/- 0.2               73.7 +/- 1.9               77.3 +/- 3.5               32.4 +/- 1.7               67.9                      \n"
     ]
    }
   ],
   "source": [
    "input_dir = \"./results_vits_3600_32\"\n",
    "latex = False\n",
    "results_file = \"results.tex\" if latex else \"results.txt\"\n",
    "\n",
    "records = reporting.load_records(input_dir)\n",
    "# selection_methods = [\n",
    "#     model_selection.IIDAccuracySelectionMethod,\n",
    "#     model_selection.OracleSelectionMethod\n",
    "# ]\n",
    "selection_methods = [\n",
    "    IIDAccuracySelectionMethod,\n",
    "    OracleSelectionMethod,\n",
    "]\n",
    "\n",
    "for selection_method in selection_methods:\n",
    "    print_results_tables(records, selection_method, latex)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T03:38:17.010401Z",
     "start_time": "2024-05-08T03:38:16.342931Z"
    }
   },
   "id": "83057a822b38d293",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T14:59:06.709065Z",
     "start_time": "2024-05-05T14:59:06.707154Z"
    }
   },
   "id": "5a5efdc1f6daa7a8",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_dir = \"./results_vits_3600\"\n",
    "count = 0\n",
    "if not os.path.exists(\"./results_vits_3600_32\"):\n",
    "    os.makedirs(\"./results_vits_3600_32\")\n",
    "for direct in os.listdir(input_dir):\n",
    "    # read the fist row of results.jsonl\n",
    "    with open(os.path.join(input_dir, direct, \"results.jsonl\")) as f:\n",
    "        first_line = f.readline()\n",
    "        first_line = json.loads(first_line)\n",
    "    if (first_line['hparams']['batch_size'] == 32 and 'MNIST' not in first_line['args']['dataset']):\n",
    "    # copy the direct to the new directory\n",
    "    #     os.system(f\"cp -r {os.path.join(input_dir, direct)} ./results_vits_3600_32\")\n",
    "        count += 1\n",
    "    elif 'MNIST' in first_line['args']['dataset'] and first_line['hparams']['batch_size'] == 64:\n",
    "        count += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T21:09:08.563217Z",
     "start_time": "2024-05-07T21:09:08.015498Z"
    }
   },
   "id": "31f299167c2fd926",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "83"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T07:51:41.609251Z",
     "start_time": "2024-05-05T07:51:41.602902Z"
    }
   },
   "id": "e44652db76e3f562",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "302bfce095b3fbd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
