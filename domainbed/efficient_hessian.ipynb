{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T06:47:35.956001Z",
     "start_time": "2024-04-28T06:47:35.952475Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Assuming the shapes are as follows:\n",
    "# A: [B, 1, m, n] - Tensor A\n",
    "# B: [1, B, n, m] - Tensor B\n",
    "B, m, n = 3, 4, 5  # Example dimensions\n",
    "# Create dummy data for demonstration\n",
    "A = torch.randn(B, 1, m, n)\n",
    "B = torch.randn(1, B, n, m)\n",
    "# Reshape A to [B, m, n] by squeezing out the singleton dimension\n",
    "A = A.squeeze(1)\n",
    "# Reshape B to [B, n, m] by squeezing and then permute to align properly\n",
    "B = B.squeeze(0)\n",
    "# Compute the batch matrix multiplication\n",
    "# We want to compute A[i] @ B[j] for all i, j\n",
    "# Expand dimensions of A and B for broadcasting to [B, 1, m, n] and [1, B, n, m]\n",
    "A_expanded = A.unsqueeze(1)  # Shape [B, 1, m, n]\n",
    "B_expanded = B.unsqueeze(0)  # Shape [1, B, n, m]\n",
    "# Perform batch matrix multiplication resulting in [B, B, m, m]\n",
    "result = torch.matmul(A_expanded, B_expanded)  # matmul auto-broadcasts the middle dimensions\n",
    "# result has shape [B, B, m, m]\n",
    "print(result.shape)  # Should print torch.Size([B, B, m, m])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T06:47:36.169103Z",
     "start_time": "2024-04-28T06:47:36.164552Z"
    }
   },
   "id": "588424c2eed63e0d",
   "execution_count": 889
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#fix seed\n",
    "torch.manual_seed(0)\n",
    "batch_size, d, num_classes, num_envs = 50, 200, 2, 2\n",
    "x = torch.randn(batch_size, d)\n",
    "y = torch.randint(0, num_classes, (batch_size,))\n",
    "logits = torch.randn(batch_size, num_classes)\n",
    "\n",
    "# suppose there are 3 environments, each samples belong to one of the 4 environments\n",
    "envs = torch.randint(0, num_envs, (batch_size,))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:19.018524Z",
     "start_time": "2024-04-29T03:11:19.013832Z"
    }
   },
   "id": "e239f6d99729a599",
   "execution_count": 1142
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def hessian(x, logits):\n",
    "    batch_size, d = x.shape  # Shape: [batch_size, d]\n",
    "    num_classes = logits.shape[1]  # Number of classes\n",
    "    dC = num_classes * d  # Total number of parameters in the flattened gradient\n",
    "\n",
    "    # Compute probabilities\n",
    "    p = F.softmax(logits, dim=1)  # Shape: [batch_size, num_classes]\n",
    "    # p[i] is the logits for the i-th example\n",
    "    \n",
    "    # Compute p_k(1-p_k) for diagonal blocks and -p_k*p_l for off-diagonal blocks\n",
    "    # Diagonal part\n",
    "    p_diag = p * (1 - p) # Shape: [batch_size, num_classes]\n",
    "    # Off-diagonal part\n",
    "    p_off_diag = -p.unsqueeze(2) * p.unsqueeze(1)  # Shape: [batch_size, num_classes, num_classes]\n",
    "    # Fill the diagonal part in off-diagonal tensor\n",
    "    indices = torch.arange(num_classes)\n",
    "    p_off_diag[:, indices, indices] = p_diag\n",
    "    \n",
    "\n",
    "    # Outer product of x\n",
    "    X_outer = torch.einsum('bi,bj->bij', x, x)  # Shape: [batch_size, d, d]\n",
    "    H2 = torch.einsum('bkl,bij->bklij', p_off_diag, X_outer) \n",
    "    H2 = H2.sum(0).reshape(dC, dC) / batch_size # Shape: [dC, dC]\n",
    "    H = torch.zeros(dC,dC)\n",
    "    for i in range(batch_size):\n",
    "        H += torch.kron(p_off_diag[i], X_outer[i])\n",
    "    H /= batch_size\n",
    "    return  H, H2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:19.848478Z",
     "start_time": "2024-04-29T03:11:19.845808Z"
    }
   },
   "id": "369336baf6d684b2",
   "execution_count": 1143
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "envs_hessian = torch.zeros(num_envs, d * num_classes, d * num_classes)\n",
    "envs_hessian2 = torch.zeros(num_envs, d * num_classes, d * num_classes)\n",
    "sum_hessian = torch.zeros(d * num_classes, d * num_classes)\n",
    "for e in range(num_envs):\n",
    "    env_mask = envs == e\n",
    "    x_env = x[env_mask]\n",
    "    logits_env = logits[env_mask]\n",
    "    H, H2 = hessian(x_env, logits_env)\n",
    "    # print(torch.norm(H, p='fro'))\n",
    "    envs_hessian[e] = H\n",
    "    envs_hessian2[e] = H2\n",
    "    sum_hessian += H\n",
    "avg_hessian = sum_hessian / num_envs\n",
    "\n",
    "# hess_penalty1 = 0\n",
    "hess_penalty2 = 0\n",
    "for e in range(num_envs):\n",
    "    env_freq = (envs == e).sum() / batch_size\n",
    "    hess_penalty2 += torch.norm(envs_hessian[e] - avg_hessian, p='fro') ** 2 * num_envs ** (-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T18:59:23.321690Z",
     "start_time": "2024-04-28T18:59:23.316697Z"
    }
   },
   "id": "2f4ae22874f78708",
   "execution_count": 1001
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0014)"
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hess_penalty2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T18:59:24.841823Z",
     "start_time": "2024-04-28T18:59:24.817003Z"
    }
   },
   "id": "878e82f8756aa62c",
   "execution_count": 1002
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3344)\n",
      "tensor(0.2968)\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_envs):\n",
    "    print(envs_hessian2[e].norm(p = 'fro')** 2) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T18:59:26.600322Z",
     "start_time": "2024-04-28T18:59:26.597082Z"
    }
   },
   "id": "94a9a7b1fc3b7974",
   "execution_count": 1003
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "def hessian_pen(logits, x, envs, num_envs):\n",
    "    \n",
    "    p = F.softmax(logits, dim=1)\n",
    "\n",
    "    diag = torch.diag_embed(p)\n",
    "     \n",
    "    off_diag = torch.einsum('bi,bj->bij', p, p)\n",
    "    \n",
    "    diff = diag - off_diag\n",
    "    prob_trace = torch.einsum('bik,cjk->bcij', diff, diff).diagonal(dim1=-2, dim2=-1).sum(-1)\n",
    "    X_outer = torch.einsum('bi,bj->bij', x, x)\n",
    "    # x_traces = torch.einsum('bik,cjk->bcij', X_outer, X_outer).diagonal(dim1=-2, dim2=-1).sum(-1)\n",
    "    x_traces = torch.zeros(batch_size, batch_size)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(i, batch_size):\n",
    "            x_traces[i, j] = torch.matmul(X_outer[i], X_outer[j]).trace()\n",
    "            x_traces[j, i] = x_traces[i, j]\n",
    "    \n",
    "    \n",
    "    env_indices = torch.arange(num_envs).unsqueeze(1)  # Shape (num_envs, 1)\n",
    "    masks = env_indices == envs\n",
    "    \n",
    "    product_matrix = prob_trace * x_traces\n",
    "    denoms = masks.sum(1).unsqueeze(1) * masks.sum(1).unsqueeze(0)\n",
    "    mask1_expanded = masks.unsqueeze(1).unsqueeze(3)  # Shape (num_envs, 1, num_samples, 1)\n",
    "    mask2_expanded = masks.unsqueeze(0).unsqueeze(2)  # Shape (1, num_envs, 1, num_samples)\n",
    "    pairwise_masks = mask1_expanded & mask2_expanded\n",
    "    \n",
    "    masked_products = pairwise_masks * product_matrix.unsqueeze(0).unsqueeze(0)\n",
    "    H_H_f = masked_products.sum(dim=-1).sum(dim=-1) / denoms\n",
    "\n",
    "    f_norm_env = H_H_f.diagonal()\n",
    "    shared_term = H_H_f.sum() / (num_envs ** 2)\n",
    "    individual_term = 2 * H_H_f.sum(dim=1) / num_envs\n",
    "    sum_h_minus_h_bar_sq = torch.sum(f_norm_env + shared_term - individual_term) / num_envs\n",
    "    sum_h_minus_h_bar_sq /= (d * num_classes)\n",
    "    \n",
    "    return f_norm_env, sum_h_minus_h_bar_sq, H_H_f\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:23.293979Z",
     "start_time": "2024-04-29T03:11:23.290059Z"
    }
   },
   "id": "540331441492a5c8",
   "execution_count": 1144
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "unique_envs = envs.unique()\n",
    "num_envs = len(unique_envs)\n",
    "H_H_f = torch.zeros(num_envs, num_envs)\n",
    "for e1 in unique_envs:\n",
    "    for e2 in unique_envs:\n",
    "        mask1 = envs == e1\n",
    "        mask2 = envs == e2\n",
    "        x_env1 = x[mask1]\n",
    "        x_env2 = x[mask2]\n",
    "        logits_env1 = logits[mask1]\n",
    "        logits_env2 = logits[mask2]\n",
    "        p1 = F.softmax(logits_env1, dim=1)\n",
    "        p2 = F.softmax(logits_env2, dim=1)\n",
    "        diag1 = torch.diag_embed(p1)\n",
    "        diag2 = torch.diag_embed(p2)\n",
    "        off_diag1 = torch.einsum('bi,bj->bij', p1, p1)\n",
    "        off_diag2 = torch.einsum('bi,bj->bij', p2, p2)\n",
    "        diff1 = diag1 - off_diag1\n",
    "        diff2 = diag2 - off_diag2\n",
    "        prob_trace_1_2 = torch.einsum('bik,cjk->bcij', diff1, diff2).diagonal(dim1=-2, dim2=-1).sum(-1)\n",
    "        X_outer1 = torch.einsum('bi,bj->bij', x_env1, x_env1)\n",
    "        X_outer2 = torch.einsum('bi,bj->bij', x_env2, x_env2)\n",
    "        x_traces_1_2 = torch.einsum('bik,cjk->bcij', X_outer1, X_outer2).diagonal(dim1=-2, dim2=-1).sum(-1)\n",
    "        H_H_f[e1, e2] = torch.sum(prob_trace_1_2 * x_traces_1_2).sum(dim=-1).sum(dim=-1) / (mask1.sum() * mask2.sum())\n",
    "\n",
    "        \n",
    "\n",
    "f_norm_env = H_H_f.diagonal()\n",
    "shared_term = H_H_f.sum() / (num_envs ** 2)\n",
    "individual_term = 2 * H_H_f.sum(dim=1) / num_envs\n",
    "sum_h_minus_h_bar_sq = torch.sum(f_norm_env + shared_term - individual_term) / num_envs\n",
    "sum_h_minus_h_bar_sq /= (d * num_classes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:23.553803Z",
     "start_time": "2024-04-29T03:11:23.497639Z"
    }
   },
   "id": "f651fd622872cd1a",
   "execution_count": 1145
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[346.3997,  30.1349],\n        [ 30.1349, 271.5005]])"
     },
     "execution_count": 1146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_H_f"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:23.710317Z",
     "start_time": "2024-04-29T03:11:23.706406Z"
    }
   },
   "id": "a271762ee038646b",
   "execution_count": 1146
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "f_norm_env, sum_h_minus_h_bar_sq2, HHf = hessian_pen(logits, x, envs, num_envs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:24.743901Z",
     "start_time": "2024-04-29T03:11:24.692986Z"
    }
   },
   "id": "3f4ae22405a10488",
   "execution_count": 1147
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3485)"
     },
     "execution_count": 1148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_h_minus_h_bar_sq2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:25.768290Z",
     "start_time": "2024-04-29T03:11:25.762130Z"
    }
   },
   "id": "c02dcc86f3f448da",
   "execution_count": 1148
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([28, 200, 200])"
     },
     "execution_count": 1149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_outer1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:26.082432Z",
     "start_time": "2024-04-29T03:11:26.077893Z"
    }
   },
   "id": "28b30c45f71fce7c",
   "execution_count": 1149
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def gradient(x, logits, y, envs):\n",
    "    # Ensure logits are in proper shape\n",
    "    \n",
    "    p = F.softmax(logits, dim=-1)\n",
    "    # Generate one-hot encoding for y\n",
    "    y_onehot = torch.zeros_like(p)\n",
    "\n",
    "    y_onehot.scatter_(1, y.long().unsqueeze(-1), 1)\n",
    "\n",
    "    # multiclasses\n",
    "    grad_w = torch.matmul((p - y_onehot).T, x) / x.size(0)\n",
    "\n",
    "    dC = grad_w.shape[0] * grad_w.shape[1]\n",
    "    # grad_w /= (dC) ** 0.25\n",
    "    # grad_w /= grad_w.shape[1] ** 0.5\n",
    "    return grad_w"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:26.409648Z",
     "start_time": "2024-04-29T03:11:26.407183Z"
    }
   },
   "id": "aa12ab4cc8e94a6a",
   "execution_count": 1150
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3485)"
     },
     "execution_count": 1151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_h_minus_h_bar_sq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:26.930549Z",
     "start_time": "2024-04-29T03:11:26.927390Z"
    }
   },
   "id": "4de6016c46e3c4a9",
   "execution_count": 1151
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[346.3997,  30.1349],\n        [ 30.1349, 271.5005]])"
     },
     "execution_count": 1152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HHf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:27.266939Z",
     "start_time": "2024-04-29T03:11:27.262698Z"
    }
   },
   "id": "9d35f99d6f8628dc",
   "execution_count": 1152
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grad_w1 = gradient(x, logits, y, envs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:11:27.847853Z",
     "start_time": "2024-04-29T03:11:27.843418Z"
    }
   },
   "id": "c80d51a83905f11b",
   "execution_count": 1153
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0406)"
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_w1.norm(p='fro') ** 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T19:05:07.351551Z",
     "start_time": "2024-04-28T19:05:07.348456Z"
    }
   },
   "id": "cf47f4094ab4534e",
   "execution_count": 1067
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0207)"
     },
     "execution_count": 1062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_w1.norm(p='fro') ** 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T19:04:44.178753Z",
     "start_time": "2024-04-28T19:04:44.174938Z"
    }
   },
   "id": "b882f1b927fd3195",
   "execution_count": 1062
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0207)"
     },
     "execution_count": 1026,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_w1.norm(p='fro') ** 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T19:02:15.114107Z",
     "start_time": "2024-04-28T19:02:15.100446Z"
    }
   },
   "id": "9371bec1795bb3b8",
   "execution_count": 1026
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])"
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T05:41:11.515170Z",
     "start_time": "2024-04-28T05:41:11.512469Z"
    }
   },
   "id": "1128f41d3d350f1",
   "execution_count": 858
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 1., 0.],\n        [0., 0., 1., 0.],\n        [1., 0., 0., 0.],\n        [1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.],\n        [0., 1., 0., 0.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.],\n        [0., 0., 1., 0.],\n        [0., 0., 1., 0.],\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 1., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 1., 0., 0.],\n        [1., 0., 0., 0.]])"
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot.scatter_(1, y.long().unsqueeze(-1), 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T05:41:20.742588Z",
     "start_time": "2024-04-28T05:41:20.739626Z"
    }
   },
   "id": "23b17f5a5684910",
   "execution_count": 859
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb49dd998e62f690"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
